{
    "model_name": "TimeLLM",
    "input_size": 10,
    "hidden_size": 50,
    "num_layers": 2,
    "output_size": 1,
    "dropout": 0.2,
    "learning_rate": 0.001,
    "batch_size": 64,
    "num_epochs": 100,
    "sequence_length": 30,
    "optimizer": "adam",
    "loss_function": "mse"
}
